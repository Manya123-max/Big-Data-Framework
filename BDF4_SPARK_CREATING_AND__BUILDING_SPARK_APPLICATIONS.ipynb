{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNhBz9ElpjPIfGqrQJyH6yC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Manya123-max/Big-Data-Framework/blob/main/BDF4_SPARK_CREATING_AND__BUILDING_SPARK_APPLICATIONS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**AIM-**To create and build a Spark session and application using PySpark, perform operations on a\n",
        "sample dataset, and verify the setup.\n"
      ],
      "metadata": {
        "id": "Iv3Ri8n06sJ4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**STEPS**"
      ],
      "metadata": {
        "id": "YhaOfz6g7qWB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 1:** Install and Setup Dependencies\n",
        "\n",
        "Purpose: Ensures all prerequisites for running Spark are met.\n",
        "\n",
        "Tasks Performed:\n",
        "1. Installing Java 8, a prerequisite for Spark.\n",
        "2. Downloading and extracting Apache Spark 3.0.0 compatible with Hadoop 2.7.\n",
        "3. Installing Findspark (to simplify Spark initialization in Python) and PySpark (Python API for Spark)."
      ],
      "metadata": {
        "id": "HbUU8rwM6xEq"
      }
    },
    {
      "metadata": {
        "id": "fUhBhrGmyAvs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e0fb558-1c3c-47c1-fc1b-5fdc5e01c9da"
      },
      "cell_type": "code",
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq\n",
        "!wget -q http://archive.apache.org/dist/spark/spark-3.0.0/spark-3.0.0-bin-hadoop2.7.tgz\n",
        "!tar xf spark-3.0.0-bin-hadoop2.7.tgz\n",
        "!pip install findspark"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: findspark in /usr/local/lib/python3.10/dist-packages (2.0.1)\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "b4Kjvk_h1AHl"
      },
      "cell_type": "markdown",
      "source": [
        "**Step 2**: Set Environment Variables\n",
        "\n",
        "1. Set Java and Spark Home Paths:\n",
        "Define the paths for Java and Spark installatio\n",
        "2. Initialize Findspark:\n",
        "Findspark is initialized to link the Spark environment\n"
      ]
    },
    {
      "metadata": {
        "id": "8Xnb_ePUyQIL"
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.0.0-bin-hadoop2.7\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NwU28K5f1H3P"
      },
      "cell_type": "markdown",
      "source": [
        "**Step 3**: Build a SparkSession\n",
        "1. Create a Spark Session:\n",
        "\n",
        "A SparkSession is built explicitly with the following parameters:\n",
        "\n",
        "master(\"local[*]\"): Indicates that the application will run locally, utilizing all available CPU cores.\n",
        "appName(\"MySparkApp\"): Names the Spark application as \"MySparkApp\".\n",
        "\n",
        "config: Additional configurations (e.g., specifying the classpath for driver dependencies"
      ]
    },
    {
      "metadata": {
        "id": "zgReRGl0y23D"
      },
      "cell_type": "code",
      "source": [
        "import findSpark\n",
        "findSpark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").appName(\"MySparkApp\").config(\"spark.some.config.option\", \"some-value\").getOrCreate()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "T3ULPx4Y1LiR"
      },
      "cell_type": "markdown",
      "source": [
        "# Use Spark!\n",
        "**Step 4:**\n",
        "1. Initializes Findspark to allow PySpark to locate the installed Spark directory.\n",
        "2. Creates a local SparkSession. The \"local[*]\" argument uses all available CPU cores for processing"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, to_date"
      ],
      "metadata": {
        "id": "N8JIxjZKmnEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Start a Spark session\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
      ],
      "metadata": {
        "id": "KtruPOaOmo_T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 5**: E-Commerce Data Analysis\n",
        "\n"
      ],
      "metadata": {
        "id": "jxjuNEvr-nvx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.Define a Sample Dataset\n",
        "\n",
        "A Python list of dictionaries is created to represent the dataset"
      ],
      "metadata": {
        "id": "XZJVozHVALH8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = [\n",
        "    (\"C001\", \"USA\", \"2024-10-01\", 5, 100, \"Laptop\"),\n",
        "    (\"C002\", \"USA\", \"2024-10-02\", 3, 60, \"Smartphone\"),\n",
        "    (\"C003\", \"India\", \"2024-10-05\", 10, 200, \"Tablet\"),\n",
        "    (\"C004\", \"India\", \"2024-10-06\", 7, 140, \"Smartwatch\"),\n",
        "    (\"C005\", \"USA\", \"2024-10-10\", 2, 40, \"Headphones\"),\n",
        "    (\"C006\", \"India\", \"2024-10-11\", 1, 20, \"Smartphone\"),\n",
        "    (\"C007\", \"UK\", \"2024-10-01\", 8, 160, \"Laptop\"),\n",
        "    (\"C008\", \"UK\", \"2024-10-15\", 6, 120, \"Smartwatch\"),\n",
        "    (\"C009\", \"USA\", \"2024-10-14\", 4, 80, \"Headphones\"),\n",
        "    (\"C010\", \"India\", \"2024-10-12\", 9, 180, \"Tablet\")\n",
        "]"
      ],
      "metadata": {
        "id": "X560JjfPmrCD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Creates a DataFrame with specified columns."
      ],
      "metadata": {
        "id": "RTANRAFbAU0w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create DataFrame from the sample data\n",
        "columns = [\"Customer_ID\", \"Country\", \"Purchase_Date\", \"Quantity\", \"Sale_Amount\"]\n",
        "df = spark.createDataFrame(data, columns)"
      ],
      "metadata": {
        "id": "kdkXU3-amuOV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Displays the first 5 rows of the dataset."
      ],
      "metadata": {
        "id": "5Q-100fCAZVX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display first 5 rows\n",
        "print(\"First 5 Rows:\")\n",
        "df.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mS7iCCTlm47C",
        "outputId": "b5ef69cf-9fef-4907-d762-3ed981aeb60c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 5 Rows:\n",
            "+-----------+-------+-------------+--------+-----------+----------+\n",
            "|Customer_ID|Country|Purchase_Date|Quantity|Sale_Amount|        _6|\n",
            "+-----------+-------+-------------+--------+-----------+----------+\n",
            "|       C001|    USA|   2024-10-01|       5|        100|    Laptop|\n",
            "|       C002|    USA|   2024-10-02|       3|         60|Smartphone|\n",
            "|       C003|  India|   2024-10-05|      10|        200|    Tablet|\n",
            "|       C004|  India|   2024-10-06|       7|        140|Smartwatch|\n",
            "|       C005|    USA|   2024-10-10|       2|         40|Headphones|\n",
            "+-----------+-------+-------------+--------+-----------+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Displays the schema of the DataFrame, showing column names and data types."
      ],
      "metadata": {
        "id": "Ed3Bbq8CAjvY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print schema\n",
        "print(\"Schema:\")\n",
        "df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xlmNUQCgm_6T",
        "outputId": "d8810a46-9f42-465f-9aba-0ba34f01836d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Schema:\n",
            "root\n",
            " |-- Customer_ID: string (nullable = true)\n",
            " |-- Country: string (nullable = true)\n",
            " |-- Purchase_Date: string (nullable = true)\n",
            " |-- Quantity: long (nullable = true)\n",
            " |-- Sale_Amount: long (nullable = true)\n",
            " |-- _6: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**OPERATIONS**"
      ],
      "metadata": {
        "id": "Yz-Zt_o0AtgS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Country with the Highest Purchase\n",
        "Groups data by country and calculates the total sales for each country.\n",
        "\n",
        "*  Groups data by country and calculates the total sales for each country.\n",
        "\n",
        "*   Orders the results in descending order of sales and retrieves the top  result.\n",
        "*   Purpose: Identify the country with the highest total sales.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "HmipkfpROk89"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Country with the highest purchase\n",
        "highest_purchase_country = df.groupBy(\"Country\").sum(\"Sale_Amount\").orderBy(col(\"sum(Sale_Amount)\").desc()).limit(1)\n",
        "highest_purchase_country.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1aEFxqnnEek",
        "outputId": "e7e61709-a5ab-4b2a-d7fa-829951d9bf7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----------------+\n",
            "|Country|sum(Sale_Amount)|\n",
            "+-------+----------------+\n",
            "|  India|             540|\n",
            "+-------+----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Number of Customers from Each Country\n",
        "\n",
        "\n",
        "*   Counts the number of customers for each country using groupBy and agg.\n",
        "\n",
        "*  Renames the resulting column for better readability.\n",
        "*   Purpose: Determine the customer distribution by country.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Pqi3rchjPFIr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Number of customers from each country\n",
        "customers_per_country = df.groupBy(\"Country\").agg({\"Customer_ID\": \"count\"}).withColumnRenamed(\"count(Customer_ID)\", \"No_of_Customers\")\n",
        "customers_per_country.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NP-0dWLNnGwQ",
        "outputId": "1b9a1ee3-77d8-4508-d3dc-bcffd791dc2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+---------------+\n",
            "|Country|No_of_Customers|\n",
            "+-------+---------------+\n",
            "|  India|              4|\n",
            "|    USA|              4|\n",
            "|     UK|              2|\n",
            "+-------+---------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Maximum Quantity Purchased by Each Customer\n",
        "\n",
        "\n",
        "*  Finds the maximum quantity purchased by each customer.\n",
        "*  Purpose: Identify customers with the highest single purchase quantity.\n",
        "\n"
      ],
      "metadata": {
        "id": "lEfrfzHVPYfu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Max quantity purchased by each customer\n",
        "max_quantity_per_customer = df.groupBy(\"Customer_ID\").agg({\"Quantity\": \"max\"}).withColumnRenamed(\"max(Quantity)\", \"Max_Quantity\")\n",
        "max_quantity_per_customer.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XI8HQmvTnLgS",
        "outputId": "9b7a5686-c24a-4b21-be82-be2129530f48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+------------+\n",
            "|Customer_ID|Max_Quantity|\n",
            "+-----------+------------+\n",
            "|       C006|           1|\n",
            "|       C010|           9|\n",
            "|       C007|           8|\n",
            "|       C003|          10|\n",
            "|       C004|           7|\n",
            "|       C009|           4|\n",
            "|       C008|           6|\n",
            "|       C005|           2|\n",
            "|       C001|           5|\n",
            "|       C002|           3|\n",
            "+-----------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Maximum Sale within a Date Range\n",
        "\n",
        "*  Converts the Purchase_Date column to a proper date format.\n",
        "\n",
        "*  Filters rows to include only those within the specified date range.\n",
        "*  Calculates the maximum sale amount within the range.\n",
        "\n",
        "\n",
        "*  Purpose: Analyze peak sales during a specific period.\n",
        "\n"
      ],
      "metadata": {
        "id": "svNCvypXPqWo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Max sale between 01.10.2024 and 15.10.2024\n",
        "df = df.withColumn(\"Purchase_Date\", to_date(col(\"Purchase_Date\"), \"yyyy-MM-dd\"))\n",
        "max_sale_in_date_range = df.filter((col(\"Purchase_Date\") >= \"2024-10-01\") & (col(\"Purchase_Date\") <= \"2024-10-15\")) \\\n",
        "    .agg({\"Sale_Amount\": \"max\"}).withColumnRenamed(\"max(Sale_Amount)\", \"Max_Sale_Between_01_10_24_and_15_10_24\")\n",
        "max_sale_in_date_range.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oySpHvuCnOb7",
        "outputId": "e59da5ce-281b-4741-857d-a31e2c5cba87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------------------------+\n",
            "|Max_Sale_Between_01_10_24_and_15_10_24|\n",
            "+--------------------------------------+\n",
            "|                                   200|\n",
            "+--------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Minimum Sale within a Date Range\n",
        "\n",
        "\n",
        "*  Similar to the previous query but calculates the minimum sale amount.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vDukdSBgP6y3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Min sale between 01.10.2024 and 15.10.2024\n",
        "min_sale_in_date_range = df.filter((col(\"Purchase_Date\") >= \"2024-10-01\") & (col(\"Purchase_Date\") <= \"2024-10-15\")) \\\n",
        "    .agg({\"Sale_Amount\": \"min\"}).withColumnRenamed(\"min(Sale_Amount)\", \"Min_Sale_Between_01_10_24_and_15_10_24\")\n",
        "min_sale_in_date_range.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gAkhJdXxnQuB",
        "outputId": "241abd6c-201d-40e4-ae11-52017a629327"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------------------------+\n",
            "|Min_Sale_Between_01_10_24_and_15_10_24|\n",
            "+--------------------------------------+\n",
            "|                                    20|\n",
            "+--------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Total Sales\n",
        "\n",
        "*  Calculates the total sales across all transactions.\n",
        "\n",
        "*   Purpose: Summarize overall sales performance."
      ],
      "metadata": {
        "id": "egdAtW6LQHwJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Total Sale\n",
        "total_sale = df.agg({\"Sale_Amount\": \"sum\"}).withColumnRenamed(\"sum(Sale_Amount)\", \"Total_Sale\")\n",
        "total_sale.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S4jjNI4-nTl8",
        "outputId": "59b39450-ec1c-492d-f572-cdd0d3ec1104"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+\n",
            "|Total_Sale|\n",
            "+----------+\n",
            "|      1100|\n",
            "+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Country with the Most Purchases\n",
        "\n",
        "\n",
        "*   Similar to the earlier query for the highest purchase country, ensuring data consistency.\n"
      ],
      "metadata": {
        "id": "orFp6aF5QWNJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. What country does most purchase?\n",
        "country_with_most_purchase = df.groupBy(\"Country\").sum(\"Sale_Amount\").orderBy(col(\"sum(Sale_Amount)\").desc()).limit(1)\n",
        "country_with_most_purchase.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KrIzPq61nXiU",
        "outputId": "cd5231b4-be40-44c1-82cc-0494aed0333b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----------------+\n",
            "|Country|sum(Sale_Amount)|\n",
            "+-------+----------------+\n",
            "|  India|             540|\n",
            "+-------+----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. Earliest Purchase by Each Customer\n",
        "\n",
        "\n",
        "*   Identifies the earliest purchase date for each customer.\n",
        "\n",
        "*   Purpose: Understand customer purchase history.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "JcgG9q8kQfmN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 8. Customer earliest purchase made by customer on e-commerce platform\n",
        "earliest_purchase = df.groupBy(\"Customer_ID\").agg({\"Purchase_Date\": \"min\"}).withColumnRenamed(\"min(Purchase_Date)\", \"Earliest_Purchase\")\n",
        "earliest_purchase.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BSpYEiV2ncyH",
        "outputId": "beb173c0-e599-4fb2-ccfd-7efb415ab40b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----------------+\n",
            "|Customer_ID|Earliest_Purchase|\n",
            "+-----------+-----------------+\n",
            "|       C006|       2024-10-11|\n",
            "|       C010|       2024-10-12|\n",
            "|       C007|       2024-10-01|\n",
            "|       C003|       2024-10-05|\n",
            "|       C004|       2024-10-06|\n",
            "|       C009|       2024-10-14|\n",
            "|       C008|       2024-10-15|\n",
            "|       C005|       2024-10-10|\n",
            "|       C001|       2024-10-01|\n",
            "|       C002|       2024-10-02|\n",
            "+-----------+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. Customer Purchase Frequency\n",
        "\n",
        "\n",
        "*  Counts the number of purchases per customer.\n",
        "*  Purpose: Measure customer engagement on the platform.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "cWNJY-krQzYL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 9. How often a customer buys something\n",
        "# Calculate the number of purchases per customer\n",
        "purchase_frequency = df.groupBy(\"Customer_ID\").agg({\"Purchase_Date\": \"count\"}).withColumnRenamed(\"count(Purchase_Date)\", \"Purchases_Per_Customer\")\n",
        "purchase_frequency.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ppEt3noKneiG",
        "outputId": "ed84d2c2-b6d8-4ca9-b371-47a79cdeaadb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+----------------------+\n",
            "|Customer_ID|Purchases_Per_Customer|\n",
            "+-----------+----------------------+\n",
            "|       C006|                     1|\n",
            "|       C010|                     1|\n",
            "|       C007|                     1|\n",
            "|       C003|                     1|\n",
            "|       C004|                     1|\n",
            "|       C009|                     1|\n",
            "|       C008|                     1|\n",
            "|       C005|                     1|\n",
            "|       C001|                     1|\n",
            "|       C002|                     1|\n",
            "+-----------+----------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 6**: Stop Spark Session\n",
        "\n",
        "Terminates the Spark session and releases resources."
      ],
      "metadata": {
        "id": "-wM7UOvURH6S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Stop SparkSession\n",
        "spark.stop()"
      ],
      "metadata": {
        "id": "Ox3-z0eKmjX6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Results**\n",
        "\n",
        "This PySpark-based application successfully accomplishes the following tasks:\n",
        "\n",
        "\n",
        "1.   Spark session was initialized successfully with proper installation and environment setup\n",
        "2.  The code successfully demonstrated execution of various analytical queries to extract meaningful insights about sales, customer behavior, and market trends from the dataset.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "dKeWbLH_RR56"
      }
    }
  ]
}